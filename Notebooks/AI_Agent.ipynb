{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0958926f",
   "metadata": {},
   "source": [
    "# Simple AI Agent\n",
    "**Using LLM to create a simple AI Agent with a tool**\n",
    "\n",
    "- program will ask the user for some input then send the input to the agent\n",
    "- response is streammed out and printed to the console\n",
    "\n",
    "**[You Tube](https://www.youtube.com/watch?v=XZdY15sHUa8)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c744e",
   "metadata": {},
   "source": [
    "### Step 1: Initialize a chat model\n",
    "### Step 2: Create An Agent Executor\n",
    "### Step 3: Get input from user and pass to the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b6ce1",
   "metadata": {},
   "source": [
    "####\n",
    "- created with `uv`: `uv init .`\n",
    "- installed `uv add langgraph langchain python-dotenv langchain-openai`\n",
    "- Open AI API Key from: https://platform.openai.com/api-keys\n",
    "    - https://platform.openai.com/docs/api-reference/introduction\n",
    "- has a simple tool that the agent can use so that it can do something beyond just a simple response\n",
    "    - you can create tools(python functions) and pass them to the agent and have them do something\n",
    "- `from langchain_openai import ChatOpenAI`\n",
    "\n",
    "#### \n",
    "- `langchain`: high level framework that allows us to build AI Applications\n",
    "- `langgraph`: complex framework that allows us to build AI Agents\n",
    "- `langchain-openai`: allows us to use open AI within LangChain and LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "# from langgraph.prebuilt import create_react_agent# The function \"create_react_agent\" is deprecated create_react_agent has been moved to `langchain.agents`\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "#==============================================================================================\n",
    "# langchain and langraph are frameworks for building AI applications.\n",
    "# langchain focuses on language models and agents.\n",
    "# langgraph focuses on building AI applications using a graph-based approach.\n",
    "# They can be used together to create powerful AI systems.\n",
    "# For more information, visit:\n",
    "# LangChain: https://langchain.com/\n",
    "# LangGraph: https://langgraph.com/\n",
    "#==============================================================================================\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "def main():\n",
    "\n",
    "    #=========================================================================================================================\n",
    "    # ChatOpenAI is a class from langchain_openai that allows interaction with OpenAI's chat models.\n",
    "    # ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "    # model=\"gpt-4\": specifies the use of the GPT-4 model\n",
    "    # temperature=0: the higher the temperature, the more creative the responses, you can use any number between 0 and 1\n",
    "    # ==========================================================================================================================\n",
    "    # TODO 1: Initialize A Chat Model\n",
    "    # ChatOpenAI() is used to create an instance of the ChatOpenAI class which is used to interact with OpenAI's chat models.\n",
    "    # temperature=0 ensures that the model's responses are more focused and deterministic\n",
    "    # ==========================================================================================================================\n",
    "    model = ChatOpenAI(temperature=0)\n",
    "\n",
    "    # tools for the agent \n",
    "    tools = []\n",
    "\n",
    "    # =============================================================================================\n",
    "    # TODO 2: Create An Agent Executor\n",
    "    # initialize an agent with the chat model\n",
    "    # create_agent() is used to create an agent that can use the specified tools to perform tasks.\n",
    "    # a function from `langchain.agents` that allows creating agents using chat models\n",
    "    # create_agent(model, tools)\n",
    "    # model: an instance of a chat model (e.g., ChatOpenAI)\n",
    "    # tools: a list of tools that the agent can use to perform tasks\n",
    "    #==============================================================================================\n",
    "    agent_executor = create_agent(model, tools=tools)\n",
    "\n",
    "    #==============================================================================================\n",
    "    # TODO 3: Interact With The Agent: Get input from user and pass to the agent_executor\n",
    "    # agent_executor.stream(): streams the agent's response in real-time\n",
    "    # {\"messages\": [HumanMessage(content=user_input)]}: formats the user's input as a message for the agent\n",
    "    #==============================================================================================\n",
    "    print(\"Hello I am your AI agent!\")\n",
    "    print(\"Ask me anything to perform calculations, or chat with me.\")\n",
    "    print(\"Type 'exit' to quit.\")\n",
    "\n",
    "\n",
    "\n",
    "        #==========================================================================================\n",
    "        # agent_executor.stream is used to get streaming responses from the agent\n",
    "        # agent_executor.stream({\"messages\": [HumanMessage(content=user_input)]})\n",
    "        # messages: a list of messages to send to the agent, in this case, we send a single human message with the user's input\n",
    "        # returns an iterator that yields chunks of the response as they are generated\n",
    "        # this allows the agent to process the input and generate a response in real-time\n",
    "        # it passes chunks of the response as they are generated, allowing for a more interactive experience\n",
    "        #==========================================================================================\n",
    "        # [HumanMessage(content=user_input)] creates a human message with the user's input\n",
    "        # this message is sent to the agent for processing\n",
    "        # HumanMessage is a class from langchain_core.messages that represents a message from a human user\n",
    "        # .stream() method to get streaming responses from the agent\n",
    "        # accepts a dictionary as input, the key is \"messages\" and\n",
    "        # messages parameter to send user input to the agent must be in the correct format\n",
    "        # format of messages: a list of HumanMessage objects\n",
    "        #==========================================================================================\n",
    "\n",
    "    user_input = input(\"\\nYou: \").strip()\n",
    "\n",
    "    # chunck will be a dictionary containing parts of the agent's response\n",
    "    for chunk in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]}\n",
    "        ):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    print(\"\\nGoodbye!\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8afffff",
   "metadata": {},
   "source": [
    "### Step 4: Allow the user to interact with the agent in a loop\n",
    "### Step 5: Define A Tool For The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade6031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "# from langgraph.prebuilt import create_react_agent# The function \"create_react_agent\" is deprecated create_react_agent has been moved to `langchain.agents`\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "# `uv init .` to initialize a new project\n",
    "#==============================================================================================\n",
    "# `uv add langchain-openai langchain-core langchain agents` to add necessary dependencies\n",
    "#==============================================================================================\n",
    "# TODO 5: Define A Tool For The Agent\n",
    "# A tool is a function that the agent can use to perform specific tasks\n",
    "# In this case, we will define a simple calculator tool that can perform addition\n",
    "#==============================================================================================\n",
    "# tool is a external service that the agent can use to perform specific tasks\n",
    "#@tool decorator to define a tool for the agent\n",
    "# the decorator takes care of registering the tool with the agent and making it available for use\n",
    "# ??????\n",
    "@tool\n",
    "def calculator_tool(x: float, y: float) -> str:\n",
    "    \"\"\"Tool to perform calculations.\"\"\"\n",
    "    try:\n",
    "        # Evaluate the mathematical expression provided in the query   \n",
    "        result = x + y# if user ask for subtr\n",
    "        print(\"Calculator_tool called with\")\n",
    "        return f\"The result of adding {x} and {y} is {result}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {e}\" \n",
    "\n",
    "def main():\n",
    "\n",
    "    model = ChatOpenAI(temperature=0)\n",
    "    tools = []\n",
    "    agent_executor = create_agent(model, tools=tools)\n",
    "\n",
    "    print(\"Hello I am your AI agent!\")\n",
    "    print(\"Ask me anything to perform calculations, or chat with me.\")\n",
    "    print(\"Type 'exit' to quit.\")\n",
    "\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        \n",
    "        if user_input == \"quit\":\n",
    "            break\n",
    "        \n",
    "        print(\"\\nAssistant: \", end=\"\")\n",
    "        for chunk in agent_executor.stream(\n",
    "            {\"messages\": [HumanMessage(content=user_input)]}\n",
    "        ):\n",
    "            \n",
    "            #==========================================================================================\n",
    "            # TODO 4: Allow the user to interact with the agent in a loop and print the agent's responses in real-time\n",
    "            # so that they can ask multiple questions and get responses without restarting the program\n",
    "            # Accessing and printing the agent's messages from the streamed chunks\n",
    "            #==========================================================================================\n",
    "            #\"agent\"(response from the agent) is a key in the chunk dictionary\n",
    "            # \"messages\"(messages from the agent) is a key in the \"agent\" dictionary\n",
    "            # chunk[\"agent\"] is a dictionary containing the agent's response\n",
    "            # chunk[\"agent\"][\"messages\"] is a list of messages from the agent\n",
    "            #==========================================================================================\n",
    "            # Explains how to access and print the agent's messages:\n",
    "                # look at the chunk dictionary for the \"agent\" key(did the chunk come from the agent?)\n",
    "                # then look for the \"messages\" key within the \"agent\" dictionary(if there are messages from the agent)\n",
    "                # iterate over the messages and print their content# iterates over the messages and prints their content \n",
    "                # without adding new lines between messages\n",
    "            #==========================================================================================\n",
    "            # if \"agent\" in chunk and \"messages\" in chunk[\"agent\"]:\n",
    "            # checks if the chunk contains agent messages\n",
    "            # for message in chunk[\"agent\"][\"messages\"]:\n",
    "            # iterates over the messages in the chunk\n",
    "            # print(message.content, end=\"\"): prints the content of each message without adding a new line\n",
    "            #==========================================================================================\n",
    "            if \"model\" in chunk and \"messages\" in chunk[\"model\"]:\n",
    "                for message in chunk[\"model\"][\"messages\"]:\n",
    "                    print(message.content, end=\"\")\n",
    "        print()\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63f575",
   "metadata": {},
   "source": [
    "\n",
    "##### Response Data format\n",
    "```python\n",
    "Assistant: {'model': \n",
    "{'messages': [AIMessage(content='Homelessness is a significant issue worldwide, with millions of people experiencing homelessness in various countries. The exact number of homeless individuals varies depending on the region and the definition of homelessness used. \\n\\nIn the United States, for example, it is estimated that over half a million people experience homelessness on any given night. In Europe, there are an estimated 700,000 homeless individuals, with countries like Germany, France, and the UK having some of the highest numbers of homeless people. \\n\\nIn developing countries, homelessness is also a major issue, with factors such as poverty, lack of affordable housing, and natural disasters contributing to the problem. In countries like India and Brazil, there are millions of people living on the streets or in informal settlements.\\n\\nOverall, homelessness is a complex issue that requires a multifaceted approach to address. Governments, non-profit organizations, and communities must work together to provide housing, support services, and resources to help individuals experiencing homelessness rebuild their lives.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 193, 'prompt_tokens': 16, 'total_tokens': 209, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Cjlh3iMQrwPyY5i31DPGOXzX7PGwH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019af3a2-e37e-7112-b56d-fac94b336b3d-0', usage_metadata={'input_tokens': 16, 'output_tokens': 193, 'total_tokens': 209, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}\n",
    "}\n",
    ")]\n",
    "}}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d58587",
   "metadata": {},
   "source": [
    "### Final\n",
    "- ask: something like `What is 5 plus 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e94d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# toll is a external service that the agent can use to perform specific tasks\n",
    "#@tool decorator to define a tool for the agent\n",
    "# the decorator takes care of registering the tool with the agent and making it available for use\n",
    "#\n",
    "@tool\n",
    "def calculator_tool(x: float, y: float) -> str:\n",
    "    \"\"\"Tool to perform calculations.\"\"\"\n",
    "    try:\n",
    "        # Evaluate the mathematical expression provided in the query   \n",
    "        result = x + y# if user ask for subtr\n",
    "        print(\"Calculator_tool called with\")\n",
    "        return f\"The result of adding {x} and {y} is {result}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {e}\" \n",
    "\n",
    "def start_agent(agent_executor):\n",
    "    print(\"Hello I am your AI agent!\")\n",
    "    print(\"Ask me anything to perform calculations, or chat with me.\")\n",
    "    print(\"Type 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        \n",
    "        if user_input == \"quit\":\n",
    "            break\n",
    "        \n",
    "        print(\"\\nAssistant: \", end=\"\")\n",
    "        for chunk in agent_executor.stream(\n",
    "            {\"messages\": [HumanMessage(content=user_input)]}\n",
    "        ):\n",
    "        #  print(chunk.keys(), end=\"\")  # Print the raw chunk for debugging\n",
    "            \n",
    "            if \"model\" in chunk and \"messages\" in chunk[\"model\"]:\n",
    "                    for message in chunk[\"model\"][\"messages\"]:\n",
    "                        print(message.content, end=\"\")\n",
    "        print()\n",
    "\n",
    "def main():\n",
    "\n",
    "    # initialize a chat model\n",
    "    model = ChatOpenAI(temperature=0)\n",
    "\n",
    "    # tools for the agent \n",
    "    tools = []\n",
    "\n",
    "\n",
    "    # initialize an agent with the chat model\n",
    "    agent_executor = create_agent(model, tools=tools)\n",
    "\n",
    "    \n",
    "\n",
    "    start_agent(agent_executor)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
